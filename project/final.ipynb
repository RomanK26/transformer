{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T21:01:04.028184Z","iopub.status.busy":"2024-02-17T21:01:04.027298Z","iopub.status.idle":"2024-02-17T21:01:06.304780Z","shell.execute_reply":"2024-02-17T21:01:06.303768Z","shell.execute_reply.started":"2024-02-17T21:01:04.028152Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["#  pip freeze > '/kaggle/working/requirement.txt'\n"]},{"cell_type":"markdown","metadata":{},"source":["# install required dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:07.248248Z","iopub.status.busy":"2024-02-19T03:22:07.247364Z","iopub.status.idle":"2024-02-19T03:22:19.392034Z","shell.execute_reply":"2024-02-19T03:22:19.390822Z","shell.execute_reply.started":"2024-02-19T03:22:07.248211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (4.66.1)\n","Requirement already satisfied: spacy in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (3.7.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (8.2.2)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (0.3.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (6.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (2.6.1)\n","Requirement already satisfied: jinja2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (3.1.2)\n","Requirement already satisfied: setuptools in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (68.2.2)\n","Requirement already satisfied: packaging>=20.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from spacy) (1.26.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tqdm spacy "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:38.249167Z","iopub.status.busy":"2024-02-19T03:22:38.248634Z","iopub.status.idle":"2024-02-19T03:22:50.257763Z","shell.execute_reply":"2024-02-19T03:22:50.256594Z","shell.execute_reply.started":"2024-02-19T03:22:38.249123Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: indic-nlp-library in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (0.92)\n","Requirement already satisfied: sphinx-argparse in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from indic-nlp-library) (0.4.0)\n","Requirement already satisfied: sphinx-rtd-theme in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from indic-nlp-library) (2.0.0)\n","Requirement already satisfied: morfessor in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from indic-nlp-library) (2.0.6)\n","Requirement already satisfied: pandas in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from indic-nlp-library) (2.1.4)\n","Requirement already satisfied: numpy in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from indic-nlp-library) (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pandas->indic-nlp-library) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pandas->indic-nlp-library) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from pandas->indic-nlp-library) (2023.4)\n","Requirement already satisfied: sphinx>=1.2.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx-argparse->indic-nlp-library) (7.2.6)\n","Requirement already satisfied: docutils<0.21 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx-rtd-theme->indic-nlp-library) (0.20.1)\n","Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n","Requirement already satisfied: six>=1.5 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n","Requirement already satisfied: sphinxcontrib-applehelp in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.8)\n","Requirement already satisfied: sphinxcontrib-devhelp in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n","Requirement already satisfied: sphinxcontrib-jsmath in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.5)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.10)\n","Requirement already satisfied: sphinxcontrib-qthelp in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n","Requirement already satisfied: Jinja2>=3.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n","Requirement already satisfied: Pygments>=2.14 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.17.2)\n","Requirement already satisfied: snowballstemmer>=2.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n","Requirement already satisfied: babel>=2.9 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.14.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n","Requirement already satisfied: imagesize>=1.3 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n","Requirement already satisfied: requests>=2.25.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n","Requirement already satisfied: packaging>=21.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.11.17)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install indic-nlp-library"]},{"cell_type":"markdown","metadata":{},"source":["# IMPORT REQUIRED LIBRARIES"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:52.095779Z","iopub.status.busy":"2024-02-19T03:22:52.095371Z","iopub.status.idle":"2024-02-19T03:22:52.104261Z","shell.execute_reply":"2024-02-19T03:22:52.103379Z","shell.execute_reply.started":"2024-02-19T03:22:52.095740Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU\n"]}],"source":["import math\n","import random\n","import time\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torch.optim import Adam\n","import torch\n","from tqdm import tqdm \n","import spacy\n","import re\n","import os\n","from IPython.display import clear_output, display\n","from indicnlp.tokenize import indic_tokenize\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from collections import Counter\n","from torch.utils.data import Dataset,DataLoader\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(\"Runnign on GPU\")\n","else:\n","    print(\"No GPU\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# EMBEDDING PART"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:54.834657Z","iopub.status.busy":"2024-02-19T03:22:54.834005Z","iopub.status.idle":"2024-02-19T03:22:54.839942Z","shell.execute_reply":"2024-02-19T03:22:54.839056Z","shell.execute_reply.started":"2024-02-19T03:22:54.834623Z"},"trusted":true},"outputs":[],"source":["class TokenEmbedding(nn.Embedding):\n","    \"\"\"\n","    Token Embedding using torch.nn\n","    they will dense representation of word using weighted matrix\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, d_model):\n","        \"\"\"\n","        class for token embedding that included positional information\n","\n","        :param vocab_size: size of vocabulary\n","        :param d_model: dimensions of model\n","        \"\"\"\n","        super().__init__(vocab_size, d_model, padding_idx=1)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:55.644829Z","iopub.status.busy":"2024-02-19T03:22:55.644068Z","iopub.status.idle":"2024-02-19T03:22:55.653748Z","shell.execute_reply":"2024-02-19T03:22:55.652707Z","shell.execute_reply.started":"2024-02-19T03:22:55.644792Z"},"trusted":true},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    \"\"\"\n","    compute sinusoid encoding.\n","    \"\"\"\n","\n","    def __init__(self, d_model, max_len, device):\n","        \"\"\"\n","        constructor of sinusoid encoding class\n","\n","        :param d_model: dimension of model\n","        :param max_len: max sequence length\n","        :param device: hardware device setting\n","        \"\"\"\n","        super(PositionalEncoding, self).__init__()\n","\n","        # same size with input matrix (for adding with input matrix)\n","        self.encoding = torch.zeros(max_len, d_model, device=device)\n","        self.encoding.requires_grad = False  # we don't need to compute gradient\n","\n","        pos = torch.arange(0, max_len, device=device)\n","        pos = pos.float().unsqueeze(dim=1)\n","        # 1D => 2D unsqueeze to represent word's position\n","\n","        _2i = torch.arange(0, d_model, step=2, device=device).float()\n","        # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n","        # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n","\n","        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n","        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n","        # compute positional encoding to consider positional information of words\n","\n","    def forward(self, x):\n","        # self.encoding\n","        # [max_len = 512, d_model = 512]\n","\n","        batch_size, seq_len = x.size()\n","        # [batch_size = 128, seq_len = 30]\n","\n","        return self.encoding[:seq_len, :]\n","        # [seq_len = 30, d_model = 512]\n","        # it will add with tok_emb : [128, 30, 512]\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:56.334702Z","iopub.status.busy":"2024-02-19T03:22:56.333885Z","iopub.status.idle":"2024-02-19T03:22:56.341622Z","shell.execute_reply":"2024-02-19T03:22:56.340603Z","shell.execute_reply.started":"2024-02-19T03:22:56.334670Z"},"trusted":true},"outputs":[],"source":["class TransformerEmbedding(nn.Module):\n","    \"\"\"\n","    token embedding + positional encoding (sinusoid)\n","    positional encoding can give positional information to network\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, d_model, max_len, drop_prob, device):\n","        \"\"\"\n","        class for word embedding that included positional information\n","\n","        :param vocab_size: size of vocabulary\n","        :param d_model: dimensions of model\n","        \"\"\"\n","        \n","        super(TransformerEmbedding, self).__init__()\n","        self.tok_emb = TokenEmbedding(vocab_size, d_model)\n","        self.pos_emb = PositionalEncoding(d_model, max_len, device)\n","        self.drop_out = nn.Dropout(p=drop_prob)\n","        self.device=device\n","        \n","\n","    def forward(self, x):\n","        x = x.long().to(self.device)\n","        tok_emb = self.tok_emb(x)\n","        pos_emb = self.pos_emb(x)\n","        return self.drop_out(tok_emb + pos_emb)"]},{"cell_type":"markdown","metadata":{},"source":["# MODEL BLOCKS"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:56.940808Z","iopub.status.busy":"2024-02-19T03:22:56.940495Z","iopub.status.idle":"2024-02-19T03:22:56.947982Z","shell.execute_reply":"2024-02-19T03:22:56.947016Z","shell.execute_reply.started":"2024-02-19T03:22:56.940785Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","        super().__init__()\n","        self.emb = TransformerEmbedding(d_model=d_model,\n","                                        max_len=max_len,\n","                                        vocab_size=enc_voc_size,\n","                                        drop_prob=drop_prob,\n","                                        device=device)\n","\n","        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n","                                                  ffn_hidden=ffn_hidden,\n","                                                  n_head=n_head,\n","                                                  drop_prob=drop_prob)\n","                                     for _ in range(n_layers)])\n","\n","    def forward(self, x, src_mask):\n","        x = self.emb(x)\n","\n","        for layer in self.layers:\n","            x = layer(x, src_mask)\n","\n","        return x"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:57.172084Z","iopub.status.busy":"2024-02-19T03:22:57.171796Z","iopub.status.idle":"2024-02-19T03:22:57.179834Z","shell.execute_reply":"2024-02-19T03:22:57.178953Z","shell.execute_reply.started":"2024-02-19T03:22:57.172059Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n","        super().__init__()\n","        self.emb = TransformerEmbedding(d_model=d_model,\n","                                        drop_prob=drop_prob,\n","                                        max_len=max_len,\n","                                        vocab_size=dec_voc_size,\n","                                        device=device)\n","\n","        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model,\n","                                                  ffn_hidden=ffn_hidden,\n","                                                  n_head=n_head,\n","                                                  drop_prob=drop_prob)\n","                                     for _ in range(n_layers)])\n","\n","        self.linear = nn.Linear(d_model, dec_voc_size)\n","\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        trg = self.emb(trg)\n","\n","        for layer in self.layers:\n","            trg = layer(trg, enc_src, trg_mask, src_mask)\n","\n","        # pass to LM head\n","        output = self.linear(trg)\n","        return output"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:58.479103Z","iopub.status.busy":"2024-02-19T03:22:58.478734Z","iopub.status.idle":"2024-02-19T03:22:58.490227Z","shell.execute_reply":"2024-02-19T03:22:58.489206Z","shell.execute_reply.started":"2024-02-19T03:22:58.479074Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","\n","    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,\n","                 ffn_hidden, n_layers, drop_prob, device):\n","        super().__init__()\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.trg_sos_idx = trg_sos_idx\n","        self.device = device\n","        self.encoder = Encoder(d_model=d_model,\n","                               n_head=n_head,\n","                               max_len=max_len,\n","                               ffn_hidden=ffn_hidden,\n","                               enc_voc_size=enc_voc_size,\n","                               drop_prob=drop_prob,\n","                               n_layers=n_layers,\n","                               device=device)\n","\n","        self.decoder = Decoder(d_model=d_model,\n","                               n_head=n_head,\n","                               max_len=max_len,\n","                               ffn_hidden=ffn_hidden,\n","                               dec_voc_size=dec_voc_size,\n","                               drop_prob=drop_prob,\n","                               n_layers=n_layers,\n","                               device=device)\n","\n","    def forward(self, src, trg):\n","        src_mask = self.make_src_mask(src)\n","        trg_mask = self.make_trg_mask(trg)\n","        enc_src = self.encoder(src, src_mask)\n","        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n","        trg_max_len = trg.size(1)\n","        output = F.pad(output, (0, max_len - trg_max_len), value=0)\n","        \n","        return output\n","\n","    def make_src_mask(self, src):\n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","        return src_mask\n","\n","    def make_trg_mask(self, trg):\n","        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n","        trg_len = trg.shape[1]\n","        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(trg.device)\n","        trg_mask = trg_pad_mask & trg_sub_mask\n","        return trg_mask"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:58.915250Z","iopub.status.busy":"2024-02-19T03:22:58.914946Z","iopub.status.idle":"2024-02-19T03:22:58.922794Z","shell.execute_reply":"2024-02-19T03:22:58.921941Z","shell.execute_reply.started":"2024-02-19T03:22:58.915225Z"},"trusted":true},"outputs":[],"source":["class ScaleDotProductAttention(nn.Module):\n","    \"\"\"\n","    compute scale dot product attention\n","\n","    Query : given sentence that we focused on (decoder)\n","    Key : every sentence to check relationship with Qeury(encoder)\n","    Value : every sentence same with Key (encoder)\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ScaleDotProductAttention, self).__init__()\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, q, k, v, mask=None, e=1e-12):\n","        # input is 4 dimension tensor\n","        # [batch_size, head, length, d_tensor]\n","        batch_size, head, length, d_tensor = k.size()\n","\n","        # 1. dot product Query with Key^T to compute similarity\n","        k_t = k.transpose(2, 3)  # transpose\n","        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n","\n","        # 2. apply masking (opt)\n","        if mask is not None:\n","            mask=mask.to(q.device)\n","            score = score.masked_fill(mask == 0, -10000)\n","\n","        # 3. pass them softmax to make [0, 1] range\n","        score = self.softmax(score)\n","\n","        # 4. multiply with Value\n","        v = score @ v\n","\n","        return v, score"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:59.442894Z","iopub.status.busy":"2024-02-19T03:22:59.442599Z","iopub.status.idle":"2024-02-19T03:22:59.453765Z","shell.execute_reply":"2024-02-19T03:22:59.452896Z","shell.execute_reply.started":"2024-02-19T03:22:59.442870Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","\n","    def __init__(self, d_model, n_head):\n","        super(MultiHeadAttention, self).__init__()\n","        self.n_head = n_head\n","        self.attention = ScaleDotProductAttention()\n","        self.w_q = nn.Linear(d_model, d_model)\n","        self.w_k = nn.Linear(d_model, d_model)\n","        self.w_v = nn.Linear(d_model, d_model)\n","        self.w_concat = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        # 1. dot product with weight matrices\n","        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n","\n","        # 2. split tensor by number of heads\n","        q, k, v = self.split(q), self.split(k), self.split(v)\n","\n","        # 3. do scale dot product to compute similarity\n","        out, attention = self.attention(q, k, v, mask=mask)\n","\n","        # 4. concat and pass to linear layer\n","        out = self.concat(out)\n","        out = self.w_concat(out)\n","\n","        # 5. visualize attention map\n","        # TODO : we should implement visualization\n","\n","        return out\n","\n","    def split(self, tensor):\n","        \"\"\"\n","        split tensor by number of head\n","\n","        :param tensor: [batch_size, length, d_model]\n","        :return: [batch_size, head, length, d_tensor]\n","        \"\"\"\n","        batch_size, length, d_model = tensor.size()\n","\n","        d_tensor = d_model // self.n_head\n","        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n","        # it is similar with group convolution (split by number of heads)\n","\n","        return tensor\n","\n","    def concat(self, tensor):\n","        \"\"\"\n","        inverse function of self.split(tensor : torch.Tensor)\n","\n","        :param tensor: [batch_size, head, length, d_tensor]\n","        :return: [batch_size, length, d_model]\n","        \"\"\"\n","        batch_size, head, length, d_tensor = tensor.size()\n","        d_model = head * d_tensor\n","\n","        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n","        return tensor\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:22:59.879176Z","iopub.status.busy":"2024-02-19T03:22:59.878595Z","iopub.status.idle":"2024-02-19T03:22:59.887162Z","shell.execute_reply":"2024-02-19T03:22:59.886086Z","shell.execute_reply.started":"2024-02-19T03:22:59.879145Z"},"trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","        super(EncoderLayer, self).__init__()\n","        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","        self.norm1 = LayerNorm(d_model=d_model)\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm2 = LayerNorm(d_model=d_model)\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x, src_mask):\n","        # 1. compute self attention\n","        _x = x\n","        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n","        \n","        # 2. add and norm\n","        x = self.dropout1(x)\n","        x = self.norm1(x + _x)\n","        \n","        # 3. positionwise feed forward network\n","        _x = x\n","        x = self.ffn(x)\n","      \n","        # 4. add and norm\n","        x = self.dropout2(x)\n","        x = self.norm2(x + _x)\n","        return x\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:00.909509Z","iopub.status.busy":"2024-02-19T03:23:00.908619Z","iopub.status.idle":"2024-02-19T03:23:00.919495Z","shell.execute_reply":"2024-02-19T03:23:00.918618Z","shell.execute_reply.started":"2024-02-19T03:23:00.909473Z"},"trusted":true},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n","        super(DecoderLayer, self).__init__()\n","        self.self_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","        self.norm1 = LayerNorm(d_model=d_model)\n","        self.dropout1 = nn.Dropout(p=drop_prob)\n","\n","        self.enc_dec_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n","        self.norm2 = LayerNorm(d_model=d_model)\n","        self.dropout2 = nn.Dropout(p=drop_prob)\n","\n","        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n","        self.norm3 = LayerNorm(d_model=d_model)\n","        self.dropout3 = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, dec, enc, trg_mask, src_mask):\n","        # 1. compute self attention\n","        _x = dec\n","        x = self.self_attention(q=dec, k=dec, v=dec, mask=trg_mask)\n","        \n","        # 2. add and norm\n","        x = self.dropout1(x)\n","        x = self.norm1(x + _x)\n","\n","        if enc is not None:\n","            # 3. compute encoder - decoder attention\n","            _x = x\n","            x = self.enc_dec_attention(q=x, k=enc, v=enc, mask=src_mask)\n","            \n","            # 4. add and norm\n","            x = self.dropout2(x)\n","            x = self.norm2(x + _x)\n","\n","        # 5. positionwise feed forward network\n","        _x = x\n","        x = self.ffn(x)\n","        \n","        # 6. add and norm\n","        x = self.dropout3(x)\n","        x = self.norm3(x + _x)\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:01.439974Z","iopub.status.busy":"2024-02-19T03:23:01.439193Z","iopub.status.idle":"2024-02-19T03:23:01.448331Z","shell.execute_reply":"2024-02-19T03:23:01.447301Z","shell.execute_reply.started":"2024-02-19T03:23:01.439935Z"},"trusted":true},"outputs":[],"source":["class LayerNorm(nn.Module):\n","    def __init__(self, d_model, eps=1e-12):\n","        super(LayerNorm, self).__init__()\n","        self.gamma = nn.Parameter(torch.ones(d_model))\n","        self.beta = nn.Parameter(torch.zeros(d_model))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        mean = x.mean(-1, keepdim=True)\n","        var = x.var(-1, unbiased=False, keepdim=True)\n","        # '-1' means last dimension. \n","\n","        out = (x - mean) / torch.sqrt(var + self.eps)\n","        out = self.gamma * out + self.beta\n","        return out\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:01.931372Z","iopub.status.busy":"2024-02-19T03:23:01.931044Z","iopub.status.idle":"2024-02-19T03:23:01.938113Z","shell.execute_reply":"2024-02-19T03:23:01.937155Z","shell.execute_reply.started":"2024-02-19T03:23:01.931342Z"},"trusted":true},"outputs":[],"source":["class PositionwiseFeedForward(nn.Module):\n","\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.linear1 = nn.Linear(d_model, hidden)\n","        self.linear2 = nn.Linear(hidden, d_model)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=drop_prob)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear2(x)\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:03.223854Z","iopub.status.busy":"2024-02-19T03:23:03.223478Z","iopub.status.idle":"2024-02-19T03:23:03.228732Z","shell.execute_reply":"2024-02-19T03:23:03.227802Z","shell.execute_reply.started":"2024-02-19T03:23:03.223823Z"},"trusted":true},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:16.862659Z","iopub.status.busy":"2024-02-19T03:23:16.862009Z","iopub.status.idle":"2024-02-19T03:23:16.875303Z","shell.execute_reply":"2024-02-19T03:23:16.874291Z","shell.execute_reply.started":"2024-02-19T03:23:16.862627Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# DATA LOADING , TOKENIZATION, VOCAB_BUILDING, TOKEN_TO_INDEX"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:18.176934Z","iopub.status.busy":"2024-02-19T03:23:18.176591Z","iopub.status.idle":"2024-02-19T03:23:24.315460Z","shell.execute_reply":"2024-02-19T03:23:24.314622Z","shell.execute_reply.started":"2024-02-19T03:23:18.176907Z"},"trusted":true},"outputs":[],"source":["\n","\n","def load_tokenizers():\n","    return indic_tokenize, spacy.load('en_core_web_sm')\n","\n","def tokenize_ne(text: str, tokenizer):\n","        return [tok for tok in tokenizer.trivial_tokenize(text)]\n","\n","\n","\n","def tokenize_en(text:str,tokenizer):\n","    return [tok.text for tok in tokenizer.tokenizer(text)]\n","\n","\n","\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, source: str, target: str):\n","        self.nepali_root = source\n","        self.english_root = target\n","        self.current=0\n","        self.max_src_len=0\n","        self.max_trg_len=0\n","        self.tokenizers =load_tokenizers()\n","        self.src_vocab=set()\n","        self.trg_vocab=set()\n","        self.src_vocab.update(['<sos>', '<eos>', '<pad>','<unk>']) \n","        self.trg_vocab.update(['<sos>', '<eos>', '<pad>','<unk>'])\n","        self.total_sentences = 0\n","        self.data = []\n","\n","        \n","        with open(self.nepali_root, 'r') as nepali, open(self.english_root, 'r') as english:\n","            for nep, eng in zip(nepali, english):\n","                tokenized_nepali = tokenize_ne(nep, self.tokenizers[0])\n","                tokenized_eng = tokenize_en(eng, self.tokenizers[1])\n","                self.total_sentences += 1\n","                self.max_src_len = max(self.max_src_len, len(tokenized_nepali))\n","                self.max_trg_len = max(self.max_trg_len, len(tokenized_eng))\n","                self.src_vocab.update(tokenized_nepali)\n","                self.trg_vocab.update(tokenized_eng)\n","                self.data.append((tokenized_nepali, tokenized_eng))\n","#                 random.shuffle(self.data)\n","\n","        \n","        self.src_vocab_dict={word: i for i, word in enumerate(self.src_vocab)}\n","        self.trg_vocab_dict={word: i for i, word in enumerate(self.trg_vocab)}\n","        \n","\n","        self.trg_pad_idx = self.trg_vocab_dict['<pad>']\n","        self.trg_sos_idx = self.trg_vocab_dict['<sos>']\n","        self.trg_eos_idx = self.trg_vocab_dict['<eos>']\n","        self.src_pad_idx = self.src_vocab_dict['<pad>']\n","        self.src_sos_idx = self.src_vocab_dict['<sos>']   \n","        self.src_eos_idx = self.src_vocab_dict['<eos>']\n","        self.src_unk_idx = self.src_vocab_dict['<unk>'] \n","        self.trg_unk_idx = self.trg_vocab_dict['<unk>']\n","        self.enc_voc_size = len(self.src_vocab)\n","        self.dec_voc_size= len(self.trg_vocab)\n","    \n","        train_ratio = 0.8\n","        val_ratio = 0.1\n","        data_len = len(self.data)\n","        train_size = int(data_len * train_ratio)\n","        val_size = int(data_len * val_ratio)\n","        test_size = data_len - train_size - val_size\n","\n","\n","        self.train_data = self.data[:train_size]\n","        self.val_data = self.data[train_size:train_size+val_size]\n","        self.test_data = self.data[train_size+val_size:]\n","  \n","\n","\n","    def __len__(self):\n","        if self.train_data:\n","            return len(self.train_data)\n","        elif self.val_data:\n","            return len(self.val_data)\n","        elif self.test_data:\n","            return len(self.test_data)\n","        else:\n","            raise ValueError(\"No data available!\")\n","\n","\n","    def __getitem__(self, idx):\n","        src, trg = self.train_data[idx]\n","        src = [self.src_vocab_dict[token] if token in self.src_vocab_dict else self.src_vocab_dict['<unk>'] for token in src]\n","        trg = [self.trg_vocab_dict[token] if token in self.trg_vocab_dict else self.trg_vocab_dict['<unk>'] for token in trg]\n","        return [src, trg]   \n","       \n","\n","\n","    def __iter__(self):\n","        return self    \n","\n","\n","\n","    def __next__(self):\n","        if self.current < len(self.train_data):\n","            self.current += 1\n","            return self.__getitem__(self.current)\n","\n","        raise StopIteration \n","\n","\n","    def printv(self):\n","        print(self.src_vocab_dict)\n","\n","           \n","\n","def custom_collate(batch, src_sos_idx, src_eos_idx, trg_sos_idx, trg_eos_idx, src_pad_idx, trg_pad_idx,src_vocab_dict:dict,trg_vocab_dict:dict):\n","    src_batch, trg_batch = zip(*batch)\n","#     print(src_batch,trg_batch)\n","    # print(\"Batch Sizes (Before Padding):\", [len(src) for src in src_batch], [len(trg) for trg in trg_batch])\n","    src_batch = [[src_vocab_dict[token] if token in src_vocab_dict else src_vocab_dict['<unk>'] for token in src] for src in src_batch]\n","    trg_batch = [[trg_vocab_dict[token] if token in trg_vocab_dict else trg_vocab_dict['<unk>'] for token in trg] for trg in trg_batch]\n","    # Pad sequences to the fixed length max_len\n","    padded_src = [torch.cat([torch.tensor([src_sos_idx]), torch.tensor(src), torch.tensor([src_eos_idx]), torch.full((max_len - len(src) - 2,), src_pad_idx, dtype=torch.long)]) for src in src_batch]\n","    padded_trg = [torch.cat([torch.tensor([trg_sos_idx]), torch.tensor(trg), torch.tensor([trg_eos_idx]), torch.full((max_len - len(trg) - 2,), trg_pad_idx, dtype=torch.long)]) for trg in trg_batch]\n","    \n","    # Stack the padded sequences\n","    padded_src = torch.stack(padded_src)\n","    padded_trg = torch.stack(padded_trg)\n","    # print(\"Batch Sizes (Before Padding):\", [len(src) for src in padded_src], [len(trg) for trg in padded_trg])\n","    # print(\"Batch Sizes (After Padding):\", padded_src.shape, padded_trg.shape)\n","    return [padded_src, padded_trg]\n","\n","         \n","\n","\n","dataset = CustomDataset('/Users/romankasichhwa/Desktop/complete/500_only/nep.txt', '/Users/romankasichhwa/Desktop/complete/500_only/eng.txt')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:26.163360Z","iopub.status.busy":"2024-02-19T03:23:26.162709Z","iopub.status.idle":"2024-02-19T03:23:26.167976Z","shell.execute_reply":"2024-02-19T03:23:26.167082Z","shell.execute_reply.started":"2024-02-19T03:23:26.163323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["21 27\n"]}],"source":["\n","print (dataset.max_src_len, dataset.max_trg_len)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:27.046874Z","iopub.status.busy":"2024-02-19T03:23:27.046138Z","iopub.status.idle":"2024-02-19T03:23:27.052417Z","shell.execute_reply":"2024-02-19T03:23:27.051436Z","shell.execute_reply.started":"2024-02-19T03:23:27.046836Z"},"trusted":true},"outputs":[],"source":["#batch_size = 128\n","batch_size = 16\n","\n","max_len = 30\n","d_model = 512\n","n_layers = 6\n","n_heads = 8\n","ffn_hidden = 1024\n","drop_prob = 0.4\n","\n","# optimizer parameter setting\n","init_lr = 1e-5\n","factor = 0.9\n","adam_eps = 5e-9\n","patience = 10\n","warmup = 100\n","epoch = 100  #1000\n","clip = 1.0\n","weight_decay = 5e-4\n","inf = float('inf')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:27.733254Z","iopub.status.busy":"2024-02-19T03:23:27.732643Z","iopub.status.idle":"2024-02-19T03:23:27.737161Z","shell.execute_reply":"2024-02-19T03:23:27.736219Z","shell.execute_reply.started":"2024-02-19T03:23:27.733221Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil"]},{"cell_type":"markdown","metadata":{},"source":["# to add /kaggle/working/result directory"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:28.812907Z","iopub.status.busy":"2024-02-19T03:23:28.812478Z","iopub.status.idle":"2024-02-19T03:23:28.817120Z","shell.execute_reply":"2024-02-19T03:23:28.816147Z","shell.execute_reply.started":"2024-02-19T03:23:28.812874Z"},"trusted":true},"outputs":[],"source":["# import os\n","\n","# result_directory = '/kaggle/working/result'\n","# os.makedirs(result_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:29.214461Z","iopub.status.busy":"2024-02-19T03:23:29.214167Z","iopub.status.idle":"2024-02-19T03:23:29.218860Z","shell.execute_reply":"2024-02-19T03:23:29.217845Z","shell.execute_reply.started":"2024-02-19T03:23:29.214437Z"},"trusted":true},"outputs":[],"source":["#to remove files from kaggle/working/result directory\n","# import os\n","\n","# result_directory = '/kaggle/working/result'\n","\n","# # List all files in the result directory\n","# files_in_result_directory = os.listdir(result_directory)\n","\n","# # Iterate through the files and remove them\n","# for file_name in files_in_result_directory:\n","#     file_path = os.path.join(result_directory, file_name)\n","#     try:\n","#         if os.path.isfile(file_path):\n","#             os.remove(file_path)\n","#             print(f\"Removed: {file_path}\")\n","#     except Exception as e:\n","#         print(f\"Error: {e}\")\n","\n","# print(\"Files in /kaggle/working/result directory removed.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# to delete the modesl from kaggle/working except kaggle/working/result"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:23:29.880639Z","iopub.status.busy":"2024-02-19T03:23:29.880275Z","iopub.status.idle":"2024-02-19T03:23:29.885489Z","shell.execute_reply":"2024-02-19T03:23:29.884459Z","shell.execute_reply.started":"2024-02-19T03:23:29.880608Z"},"trusted":true},"outputs":[],"source":["# root_dir = \"/kaggle/working\"\n","# excluded_dir = \"result\"\n","\n","# # Get all files and directories in the root directory\n","# all_items = os.listdir(root_dir)\n","\n","# # Filter out the excluded directory\n","# items_to_delete = [item for item in all_items if item != excluded_dir]\n","\n","# # Delete each item (file or directory)\n","# for item in items_to_delete:\n","#     item_path = os.path.join(root_dir, item)\n","#     if os.path.isdir(item_path):\n","#         shutil.rmtree(item_path)  # Use shutil.rmtree for directories\n","#     else:\n","#         os.remove(item_path)\n","\n","# print(f\"Successfully deleted all items except '{excluded_dir}' in {root_dir}.\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:46:23.173166Z","iopub.status.busy":"2024-02-19T03:46:23.172239Z","iopub.status.idle":"2024-02-19T03:46:23.185841Z","shell.execute_reply":"2024-02-19T03:46:23.184813Z","shell.execute_reply.started":"2024-02-19T03:46:23.173131Z"},"trusted":true},"outputs":[],"source":["def bleu_stats(hypothesis, reference):\n","    \"\"\"Compute statistics for BLEU.\"\"\"\n","    stats = []\n","    stats.append(len(hypothesis))\n","    stats.append(len(reference))\n","    for n in range(1, 5):\n","        s_ngrams = Counter(\n","            [tuple(hypothesis[i:i + n]) for i in range(len(hypothesis) + 1 - n)]\n","        )\n","        r_ngrams = Counter(\n","            [tuple(reference[i:i + n]) for i in range(len(reference) + 1 - n)]\n","        )\n","\n","        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n","        stats.append(max([len(hypothesis) + 1 - n, 0]))\n","    return stats\n","\n","\n","def bleu(stats):\n","    \"\"\"Compute BLEU given n-gram statistics.\"\"\"\n","    if len(list(filter(lambda x: x == 0, stats))) > 0:\n","        return 0\n","    (c, r) = stats[:2]\n","    log_bleu_prec = sum(\n","        [math.log(float(x) / y) for x, y in zip(stats[2::2], stats[3::2])]\n","    ) / 4.\n","    return math.exp(min([0, 1 - float(r) / c]) + log_bleu_prec)\n","\n","\n","def get_bleu(hypotheses, reference):\n","    \"\"\"Get validation BLEU score for dev set.\"\"\"\n","    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","    for hyp, ref in zip(hypotheses, reference):\n","        stats += np.array(bleu_stats(hyp, ref))\n","    return 100 * bleu(stats)\n","\n","\n","def idx_to_word(x, vocab):\n","    words = []\n","    for i in x:\n","        word = next((word for word, index in vocab.items() if index == i), None)\n","        if word is not None and '<' not in word:\n","            words.append(word)\n","    words = \" \".join(words)\n","    return words"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T03:47:40.848900Z","iopub.status.busy":"2024-02-19T03:47:40.848493Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 34,473,713 trainable parameters\n"]},{"name":"stderr","output_type":"stream","text":["/Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  _torch_pytree._register_pytree_node(\n","/Users/romankasichhwa/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","Training:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [19, 9, 14, 14, 17, 17, 8, 10] [23, 11, 14, 19, 22, 17, 11, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 1/50 [00:00<00:29,  1.65it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 17, 9, 8, 11, 15, 16, 12] [14, 25, 10, 9, 11, 20, 21, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   4%|▍         | 2/50 [00:01<00:24,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 7, 16, 9, 13, 14, 11, 9] [12, 8, 19, 10, 21, 20, 11, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   6%|▌         | 3/50 [00:01<00:20,  2.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 17, 10, 4, 7, 9, 14, 10] [8, 16, 10, 9, 9, 10, 16, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   8%|▊         | 4/50 [00:01<00:19,  2.42it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 11, 8, 13, 10, 11, 12, 16] [27, 14, 12, 19, 9, 11, 13, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  10%|█         | 5/50 [00:02<00:19,  2.29it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 13, 12, 12, 11, 15, 11, 9] [16, 16, 13, 18, 12, 21, 15, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  12%|█▏        | 6/50 [00:02<00:18,  2.40it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 14, 12, 9, 9, 9, 12, 12] [12, 17, 14, 10, 11, 11, 14, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  14%|█▍        | 7/50 [00:03<00:17,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 11, 9, 16, 12, 12, 14, 12] [10, 13, 9, 22, 19, 21, 20, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  16%|█▌        | 8/50 [00:03<00:16,  2.56it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 8, 19, 10, 10, 14, 12, 7] [16, 8, 23, 12, 14, 16, 14, 6]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  18%|█▊        | 9/50 [00:03<00:18,  2.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 15, 13, 10, 13, 15, 15, 10] [19, 14, 14, 11, 11, 16, 18, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  20%|██        | 10/50 [00:04<00:23,  1.68it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 10, 9, 17, 11, 11, 11, 19] [17, 16, 15, 19, 10, 13, 15, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  22%|██▏       | 11/50 [00:05<00:21,  1.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 12, 15, 11, 15, 8, 1, 16] [16, 16, 19, 18, 19, 9, 2, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  24%|██▍       | 12/50 [00:05<00:21,  1.73it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 10, 5, 2, 16, 12, 11] [16, 7, 8, 4, 3, 17, 13, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  26%|██▌       | 13/50 [00:06<00:19,  1.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 13, 10, 16, 10, 10, 16, 17] [17, 12, 9, 16, 11, 8, 20, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  28%|██▊       | 14/50 [00:06<00:17,  2.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 8, 6, 11, 11, 7, 17, 14] [17, 11, 6, 12, 11, 9, 22, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  30%|███       | 15/50 [00:07<00:16,  2.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 9, 8, 7, 14, 10, 11, 8] [15, 10, 8, 7, 13, 10, 11, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  32%|███▏      | 16/50 [00:07<00:16,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 14, 10, 10, 18, 14, 9, 10] [14, 19, 10, 15, 17, 16, 10, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  34%|███▍      | 17/50 [00:08<00:16,  2.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 11, 10, 7, 14, 10, 9, 13] [18, 11, 9, 11, 18, 13, 10, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  36%|███▌      | 18/50 [00:08<00:17,  1.87it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 18, 14, 15, 15, 8, 10, 10] [9, 16, 14, 26, 12, 9, 10, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  38%|███▊      | 19/50 [00:09<00:15,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 8, 10, 12, 11, 12, 8, 17] [10, 10, 11, 13, 10, 16, 10, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  40%|████      | 20/50 [00:09<00:15,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 15, 17, 9, 11, 10, 8, 16] [13, 19, 19, 11, 13, 12, 9, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  42%|████▏     | 21/50 [00:10<00:14,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 14, 12, 18, 16, 15, 11, 13] [15, 17, 20, 21, 19, 22, 11, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  44%|████▍     | 22/50 [00:10<00:13,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 14, 3, 15, 15, 17, 9, 9] [10, 16, 4, 15, 18, 18, 10, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  46%|████▌     | 23/50 [00:11<00:12,  2.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 12, 5, 12, 10, 18, 16, 17] [17, 11, 4, 13, 8, 22, 20, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  48%|████▊     | 24/50 [00:11<00:11,  2.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [18, 12, 11, 8, 15, 14, 11, 12] [18, 13, 16, 10, 13, 18, 15, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  50%|█████     | 25/50 [00:12<00:11,  2.24it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 10, 11, 7, 17, 7, 9, 11] [14, 17, 12, 7, 20, 9, 10, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  52%|█████▏    | 26/50 [00:12<00:10,  2.29it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 10, 12, 5, 13, 11, 19, 9] [15, 11, 13, 6, 17, 18, 18, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  54%|█████▍    | 27/50 [00:12<00:10,  2.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 15, 11, 8, 10, 10, 14, 14] [23, 17, 9, 9, 13, 10, 18, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  56%|█████▌    | 28/50 [00:13<00:10,  2.19it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 7, 17, 11, 15, 15, 9] [19, 12, 11, 16, 9, 16, 17, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  58%|█████▊    | 29/50 [00:13<00:09,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 11, 18, 15, 12, 10, 11, 19] [18, 12, 15, 13, 19, 13, 13, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  60%|██████    | 30/50 [00:14<00:09,  2.15it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 17, 13, 12, 10, 13, 10, 17] [21, 22, 16, 13, 16, 16, 12, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  62%|██████▏   | 31/50 [00:14<00:08,  2.24it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 14, 10, 7, 13, 9, 7] [12, 15, 18, 12, 9, 17, 12, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  64%|██████▍   | 32/50 [00:15<00:07,  2.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 7, 12, 17, 15, 8, 12, 11] [13, 9, 15, 15, 18, 10, 18, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  66%|██████▌   | 33/50 [00:15<00:07,  2.36it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 15, 10, 16, 11, 11, 16, 16] [13, 15, 10, 17, 17, 13, 20, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  68%|██████▊   | 34/50 [00:16<00:07,  2.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 9, 12, 13, 6, 15, 13, 9] [15, 12, 13, 19, 8, 18, 16, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  70%|███████   | 35/50 [00:16<00:07,  2.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 12, 9, 3, 11, 16, 9, 10] [11, 13, 11, 4, 11, 20, 10, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  72%|███████▏  | 36/50 [00:17<00:06,  2.10it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 11, 9, 16, 11, 17, 14, 10] [9, 15, 11, 15, 10, 18, 14, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  74%|███████▍  | 37/50 [00:17<00:05,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [19, 15, 17, 10, 9, 9, 13, 10] [16, 11, 21, 10, 11, 10, 13, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  76%|███████▌  | 38/50 [00:17<00:05,  2.23it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 14, 12, 10, 10, 13, 14, 10] [14, 16, 15, 8, 9, 20, 18, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  78%|███████▊  | 39/50 [00:18<00:04,  2.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [19, 16, 11, 10, 13, 10, 14, 15] [18, 20, 14, 8, 11, 10, 18, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  80%|████████  | 40/50 [00:18<00:04,  2.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 11, 14, 10, 10, 10, 14, 11] [10, 14, 20, 12, 17, 8, 16, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  82%|████████▏ | 41/50 [00:19<00:04,  2.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 16, 16, 9, 9, 10, 13, 14] [19, 21, 20, 10, 9, 8, 16, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  84%|████████▍ | 42/50 [00:19<00:03,  2.15it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 18, 8, 16, 18, 10, 15, 13] [11, 17, 9, 20, 21, 15, 17, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  86%|████████▌ | 43/50 [00:20<00:03,  2.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 12, 16, 17, 18, 8, 8, 8] [10, 12, 13, 22, 19, 13, 8, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  88%|████████▊ | 44/50 [00:20<00:02,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 15, 8, 14, 12, 12, 18, 15] [13, 19, 11, 23, 10, 13, 22, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  90%|█████████ | 45/50 [00:21<00:02,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 13, 14, 10, 14, 13, 8, 12] [14, 15, 12, 17, 17, 16, 8, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  92%|█████████▏| 46/50 [00:21<00:01,  2.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 13, 9, 11, 13, 12, 16, 10] [9, 14, 11, 16, 12, 13, 17, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  94%|█████████▍| 47/50 [00:22<00:01,  2.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 15, 10, 3, 13, 15, 8, 1] [17, 17, 12, 4, 17, 21, 9, 4]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  96%|█████████▌| 48/50 [00:22<00:00,  2.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 8, 18, 15, 11, 12, 12, 10] [9, 9, 16, 16, 14, 14, 13, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  98%|█████████▊| 49/50 [00:23<00:00,  2.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 13, 14, 14, 14, 14, 15] [11, 17, 14, 14, 16, 17, 21]\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 50/50 [00:23<00:00,  2.14it/s]\n","Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 14, 16, 16, 16, 16, 11, 16] [20, 18, 20, 20, 20, 19, 15, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  14%|█▍        | 1/7 [00:01<00:06,  1.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 11, 16, 14, 16, 17, 12, 16] [20, 14, 20, 18, 20, 16, 13, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  29%|██▊       | 2/7 [00:02<00:04,  1.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 17, 10, 11, 9, 13, 17, 14] [16, 21, 12, 12, 10, 13, 15, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  43%|████▎     | 3/7 [00:03<00:04,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 10, 17, 18, 9, 10, 13] [15, 11, 12, 19, 18, 11, 11, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  57%|█████▋    | 4/7 [00:04<00:03,  1.00s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 8, 16, 13, 16, 12, 12, 8] [13, 10, 14, 12, 18, 12, 12, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  71%|███████▏  | 5/7 [00:05<00:02,  1.00s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 13, 13, 12, 13, 17, 14, 12] [21, 16, 14, 18, 23, 18, 14, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11] [19]\n","Epoch: 1 | Time: 0m 29s\n","\tTrain Loss: 6.466 | Train PPL: 642.692 | Train Accuracy: 22.919 %\n","\tVal Loss: 9.169 |  Val PPL: 9593.474 | Val Accuracy: 0.000 %\n","\tBLEU Score: 0.424\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 14, 8, 12, 10, 18, 13, 15] [11, 18, 9, 16, 12, 21, 10, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 1/50 [00:00<00:28,  1.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 12, 15, 13, 16, 16, 10, 8] [17, 14, 21, 13, 13, 20, 11, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   4%|▍         | 2/50 [00:01<00:25,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 13, 9, 12, 14, 17, 6, 8] [11, 13, 11, 18, 14, 18, 8, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   6%|▌         | 3/50 [00:01<00:23,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 5, 15, 15, 11, 12, 10, 9] [22, 4, 17, 21, 12, 15, 9, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   8%|▊         | 4/50 [00:01<00:22,  2.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 13, 10, 3, 9, 7, 16, 14] [11, 19, 10, 4, 9, 11, 21, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  10%|█         | 5/50 [00:02<00:23,  1.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 11, 14, 15, 11, 9, 12, 13] [19, 18, 19, 13, 15, 10, 14, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  12%|█▏        | 6/50 [00:02<00:21,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 17, 15, 10, 14, 14, 7] [15, 12, 15, 13, 11, 23, 19, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  14%|█▍        | 7/50 [00:03<00:21,  2.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 11, 12, 10, 17, 10, 18, 15] [15, 10, 15, 8, 22, 12, 21, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  16%|█▌        | 8/50 [00:04<00:21,  1.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 7, 10, 11, 7, 10, 14] [10, 14, 9, 9, 10, 9, 8, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  18%|█▊        | 9/50 [00:04<00:20,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 8, 15, 10, 1, 13, 10, 5] [18, 8, 22, 13, 4, 16, 10, 4]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  20%|██        | 10/50 [00:05<00:19,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 9, 12, 8, 15, 9, 13, 9] [13, 9, 17, 9, 20, 7, 14, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  22%|██▏       | 11/50 [00:05<00:19,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 10, 14, 10, 12, 14, 14] [13, 16, 8, 16, 15, 13, 16, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  24%|██▍       | 12/50 [00:06<00:19,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 11, 17, 10, 15, 12, 7, 10] [9, 11, 21, 12, 17, 11, 9, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  26%|██▌       | 13/50 [00:06<00:18,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 15, 11, 8, 11, 12, 10, 16] [6, 27, 17, 11, 12, 15, 8, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  28%|██▊       | 14/50 [00:07<00:17,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 11, 8, 12, 13, 15, 13] [12, 12, 14, 9, 13, 20, 15, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  30%|███       | 15/50 [00:07<00:17,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 15, 14, 15, 17, 17, 13, 9] [8, 19, 18, 26, 22, 22, 14, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  32%|███▏      | 16/50 [00:08<00:19,  1.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [18, 8, 11, 14, 16, 13, 11, 9] [17, 11, 15, 18, 17, 11, 13, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  34%|███▍      | 17/50 [00:08<00:18,  1.79it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 12, 16, 10, 16, 16, 13, 17] [10, 12, 20, 10, 20, 19, 16, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  36%|███▌      | 18/50 [00:09<00:20,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 14, 14, 16, 17, 17, 14, 12] [14, 19, 16, 19, 18, 17, 14, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  38%|███▊      | 19/50 [00:10<00:20,  1.50it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 16, 9, 13, 14, 18, 10, 18] [13, 20, 12, 16, 17, 22, 10, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  40%|████      | 20/50 [00:10<00:19,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 10, 14, 7, 8, 10, 10] [8, 14, 17, 20, 7, 13, 9, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  42%|████▏     | 21/50 [00:11<00:18,  1.59it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 11, 11, 19, 12, 12, 10, 16] [11, 14, 9, 18, 13, 13, 12, 21]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  44%|████▍     | 22/50 [00:12<00:18,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 12, 18, 14, 12, 17, 13, 15] [16, 13, 17, 13, 13, 20, 12, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  46%|████▌     | 23/50 [00:12<00:15,  1.70it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 8, 8, 9, 11, 11, 12, 10] [10, 8, 8, 10, 12, 13, 13, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  48%|████▊     | 24/50 [00:13<00:14,  1.82it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 9, 8, 8, 14, 8, 13, 10] [17, 12, 10, 9, 14, 8, 13, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  50%|█████     | 25/50 [00:13<00:12,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 14, 15, 8, 15, 14, 19, 14] [12, 14, 18, 10, 14, 17, 23, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  52%|█████▏    | 26/50 [00:13<00:11,  2.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 9, 16, 13, 9, 15, 15] [10, 10, 10, 17, 15, 10, 17, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  54%|█████▍    | 27/50 [00:14<00:10,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 10, 8, 15, 14, 16, 7] [11, 10, 9, 8, 22, 17, 19, 7]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  56%|█████▌    | 28/50 [00:14<00:10,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 11, 14, 10, 11, 12, 11, 14] [17, 9, 16, 12, 14, 18, 10, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  58%|█████▊    | 29/50 [00:15<00:09,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 12, 18, 13, 16, 15, 11] [8, 10, 14, 19, 12, 22, 18, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  60%|██████    | 30/50 [00:15<00:09,  2.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 11, 13, 11, 12, 13, 12, 8] [15, 13, 16, 11, 18, 16, 19, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  62%|██████▏   | 31/50 [00:16<00:08,  2.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 12, 9, 15, 15, 9, 14, 9] [16, 15, 11, 15, 21, 10, 17, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  64%|██████▍   | 32/50 [00:16<00:08,  2.16it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 13, 19, 16, 12, 10, 14, 10] [20, 19, 19, 20, 13, 12, 20, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  66%|██████▌   | 33/50 [00:17<00:07,  2.15it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 17, 18, 16, 12, 14, 12, 8] [18, 25, 15, 20, 15, 12, 18, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  68%|██████▊   | 34/50 [00:17<00:08,  1.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 13, 11, 9, 10, 10, 7, 7] [17, 17, 18, 11, 17, 17, 8, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  70%|███████   | 35/50 [00:18<00:07,  2.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 9, 10, 11, 15, 14, 18, 11] [8, 10, 10, 15, 19, 16, 18, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  72%|███████▏  | 36/50 [00:18<00:07,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 9, 16, 9, 12, 12, 9, 8] [20, 11, 19, 15, 21, 13, 10, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  74%|███████▍  | 37/50 [00:19<00:06,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 10, 19, 3, 11, 12, 10, 8] [13, 9, 18, 4, 13, 16, 11, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  76%|███████▌  | 38/50 [00:19<00:05,  2.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 15, 11, 13, 11, 9, 11, 15] [21, 19, 17, 16, 16, 10, 12, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  78%|███████▊  | 39/50 [00:20<00:05,  2.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [18, 6, 10, 10, 12, 15, 16, 7] [22, 6, 8, 11, 14, 18, 17, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  80%|████████  | 40/50 [00:20<00:04,  2.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 15, 16, 9, 16, 8, 11, 17] [16, 16, 17, 11, 20, 10, 11, 23]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  82%|████████▏ | 41/50 [00:21<00:04,  2.11it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 10, 9, 4, 11, 9, 13, 17] [9, 16, 11, 9, 11, 10, 11, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  84%|████████▍ | 42/50 [00:21<00:03,  2.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 7, 15, 9, 12, 11, 11, 17] [19, 8, 16, 11, 13, 11, 12, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  86%|████████▌ | 43/50 [00:22<00:03,  1.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 12, 9, 12, 10, 3, 8, 9] [9, 14, 10, 11, 15, 4, 9, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  88%|████████▊ | 44/50 [00:22<00:03,  1.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 19, 12, 16, 13, 10, 17] [21, 11, 18, 13, 17, 19, 10, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  90%|█████████ | 45/50 [00:23<00:02,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 13, 12, 1, 8, 15, 11] [11, 10, 14, 10, 2, 9, 17, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  92%|█████████▏| 46/50 [00:23<00:02,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 14, 17, 5, 13, 19, 14, 11] [11, 17, 19, 6, 14, 16, 18, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  94%|█████████▍| 47/50 [00:24<00:01,  1.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 18, 13, 11, 13, 9, 12, 15] [18, 16, 17, 16, 16, 10, 13, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  96%|█████████▌| 48/50 [00:24<00:01,  1.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 9, 2, 8, 14, 11, 17, 16] [16, 12, 3, 11, 16, 13, 14, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  98%|█████████▊| 49/50 [00:25<00:00,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 8, 7, 14, 19, 12, 11] [16, 9, 9, 18, 23, 19, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n","Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 14, 16, 16, 16, 16, 11, 16] [20, 18, 20, 20, 20, 19, 15, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  14%|█▍        | 1/7 [00:01<00:06,  1.08s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 11, 16, 14, 16, 17, 12, 16] [20, 14, 20, 18, 20, 16, 13, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  29%|██▊       | 2/7 [00:02<00:05,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 17, 10, 11, 9, 13, 17, 14] [16, 21, 12, 12, 10, 13, 15, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  43%|████▎     | 3/7 [00:03<00:04,  1.12s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 10, 17, 18, 9, 10, 13] [15, 11, 12, 19, 18, 11, 11, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  57%|█████▋    | 4/7 [00:04<00:03,  1.13s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 8, 16, 13, 16, 12, 12, 8] [13, 10, 14, 12, 18, 12, 12, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  71%|███████▏  | 5/7 [00:05<00:02,  1.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 13, 13, 12, 13, 17, 14, 12] [21, 16, 14, 18, 23, 18, 14, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 7/7 [00:06<00:00,  1.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11] [19]\n","Epoch: 2 | Time: 0m 32s\n","\tTrain Loss: 4.947 | Train PPL: 140.719 | Train Accuracy: 48.241 %\n","\tVal Loss: 8.669 |  Val PPL: 5821.110 | Val Accuracy: 0.000 %\n","\tBLEU Score: 0.424\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 12, 16, 9, 12, 13, 13, 12] [10, 20, 17, 11, 14, 19, 14, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 1/50 [00:00<00:32,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 15, 8, 14, 12, 9, 17, 10] [9, 21, 10, 20, 13, 9, 20, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   4%|▍         | 2/50 [00:01<00:24,  1.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 11, 9, 16, 11, 14, 18, 1] [14, 13, 10, 20, 13, 18, 15, 4]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   6%|▌         | 3/50 [00:01<00:23,  2.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 10, 8, 14, 14, 10, 12] [9, 15, 10, 10, 19, 12, 11, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   8%|▊         | 4/50 [00:01<00:21,  2.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 8, 8, 13, 10, 8, 15, 17] [13, 9, 10, 19, 12, 8, 16, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  10%|█         | 5/50 [00:02<00:22,  2.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 17, 14, 17, 8, 11, 12, 16] [11, 22, 17, 22, 9, 11, 13, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  12%|█▏        | 6/50 [00:02<00:20,  2.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 7, 9, 9, 15, 9, 19] [7, 10, 9, 11, 15, 17, 10, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  14%|█▍        | 7/50 [00:03<00:20,  2.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [3, 13, 13, 12, 6, 11, 13, 7] [4, 17, 16, 15, 8, 17, 17, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  16%|█▌        | 8/50 [00:03<00:19,  2.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 18, 13, 3, 14, 9, 17, 11] [9, 19, 12, 4, 19, 12, 19, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  18%|█▊        | 9/50 [00:04<00:18,  2.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 11, 7, 7, 15, 14, 14, 15] [11, 11, 9, 9, 15, 14, 17, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  20%|██        | 10/50 [00:04<00:18,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 17, 9, 10, 15, 10, 15, 13] [16, 22, 10, 11, 17, 9, 11, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  22%|██▏       | 11/50 [00:05<00:18,  2.14it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 12, 11, 7, 16, 11, 9, 11] [20, 13, 14, 10, 20, 9, 10, 12]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  24%|██▍       | 12/50 [00:05<00:18,  2.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 9, 15, 12, 8, 12, 5, 15] [10, 11, 27, 16, 9, 13, 4, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  26%|██▌       | 13/50 [00:06<00:22,  1.66it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [7, 9, 8, 8, 15, 13, 16, 11] [8, 11, 11, 10, 18, 13, 22, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  28%|██▊       | 14/50 [00:07<00:21,  1.69it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 11, 17, 11, 14, 14, 17, 9] [13, 16, 18, 16, 17, 14, 21, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  30%|███       | 15/50 [00:07<00:19,  1.84it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 8, 16, 12, 13, 12, 7] [12, 17, 9, 17, 18, 10, 11, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  32%|███▏      | 16/50 [00:08<00:17,  1.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 16, 11, 8, 9, 10, 8, 9] [14, 21, 14, 9, 10, 12, 11, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  34%|███▍      | 17/50 [00:08<00:15,  2.10it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 13, 12, 10, 14, 2, 11, 8] [15, 17, 17, 13, 16, 3, 13, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  36%|███▌      | 18/50 [00:08<00:15,  2.09it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 13, 18, 12, 6, 12, 12, 10] [9, 13, 22, 13, 6, 19, 18, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  38%|███▊      | 19/50 [00:09<00:14,  2.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 7, 10, 14, 11, 9, 14, 15] [9, 7, 10, 16, 10, 10, 16, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  40%|████      | 20/50 [00:09<00:14,  2.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 3, 15, 14, 15, 11, 12, 13] [14, 4, 19, 23, 18, 15, 15, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  42%|████▏     | 21/50 [00:10<00:13,  2.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 19, 15, 16, 15, 8, 8, 14] [19, 18, 17, 13, 12, 9, 9, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  44%|████▍     | 22/50 [00:10<00:13,  2.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 10, 12, 13, 15, 9, 9, 10] [14, 11, 15, 13, 17, 11, 11, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  46%|████▌     | 23/50 [00:11<00:15,  1.79it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 10, 11, 13, 11, 9, 10, 9] [18, 12, 15, 13, 17, 10, 10, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  48%|████▊     | 24/50 [00:12<00:14,  1.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [18, 10, 16, 11, 10, 10, 9, 10] [17, 12, 19, 13, 9, 12, 10, 10]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  50%|█████     | 25/50 [00:12<00:13,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [18, 13, 14, 14, 7, 15, 11, 17] [18, 22, 14, 18, 7, 22, 18, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  52%|█████▏    | 26/50 [00:13<00:11,  2.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 16, 8, 11, 10, 13, 12, 7] [13, 17, 9, 11, 8, 16, 14, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  54%|█████▍    | 27/50 [00:13<00:10,  2.13it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 19, 10, 15, 12, 11, 14, 11] [11, 16, 10, 17, 11, 14, 14, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  56%|█████▌    | 28/50 [00:13<00:10,  2.12it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 19, 17, 14, 9, 14, 5, 14] [16, 23, 23, 17, 10, 18, 6, 17]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  58%|█████▊    | 29/50 [00:14<00:09,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 10, 16, 9, 10, 10, 9, 12] [8, 8, 17, 12, 8, 16, 11, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  60%|██████    | 30/50 [00:14<00:08,  2.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 12, 17, 14, 16, 19, 12, 12] [10, 13, 25, 19, 17, 19, 15, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  62%|██████▏   | 31/50 [00:15<00:08,  2.26it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [9, 10, 10, 10, 13, 12, 18, 13] [11, 8, 16, 17, 16, 13, 22, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  64%|██████▍   | 32/50 [00:15<00:08,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 8, 5, 4, 9, 8, 14, 9] [11, 12, 4, 9, 10, 8, 17, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  66%|██████▌   | 33/50 [00:16<00:08,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 10, 10, 10, 16, 10, 9, 16] [16, 12, 12, 13, 17, 17, 12, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  68%|██████▊   | 34/50 [00:16<00:08,  1.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 7, 12, 12, 10, 11, 13, 16] [11, 6, 13, 21, 17, 16, 17, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  70%|███████   | 35/50 [00:17<00:08,  1.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [17, 19, 12, 10, 15, 17, 14, 15] [17, 18, 12, 11, 19, 16, 14, 19]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  72%|███████▏  | 36/50 [00:18<00:08,  1.75it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 9, 18, 13, 14, 12, 18, 14] [19, 10, 21, 16, 16, 10, 16, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  74%|███████▍  | 37/50 [00:18<00:07,  1.82it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 16, 14, 10, 15, 9, 10, 18] [8, 19, 20, 10, 13, 11, 10, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  76%|███████▌  | 38/50 [00:19<00:06,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 10, 16, 8, 9, 10, 11, 18] [13, 15, 21, 8, 10, 14, 12, 21]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  78%|███████▊  | 39/50 [00:19<00:06,  1.78it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [12, 12, 7, 9, 10, 11, 11, 8] [16, 14, 8, 10, 10, 11, 12, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  80%|████████  | 40/50 [00:20<00:05,  1.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 13, 11, 17, 10, 13, 7, 19] [12, 12, 14, 17, 14, 19, 9, 23]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  82%|████████▏ | 41/50 [00:20<00:04,  1.84it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 17, 13, 17, 14, 12, 14, 1] [15, 22, 16, 21, 20, 14, 18, 2]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  84%|████████▍ | 42/50 [00:21<00:04,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 10, 14, 9, 8, 11, 14, 16] [16, 13, 13, 12, 11, 13, 19, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  86%|████████▌ | 43/50 [00:21<00:03,  1.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 12, 15, 12, 10, 13, 15, 9] [16, 13, 18, 13, 12, 14, 26, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  88%|████████▊ | 44/50 [00:22<00:03,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 11, 11, 11, 11, 8, 15, 10] [9, 11, 12, 12, 17, 10, 20, 9]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  90%|█████████ | 45/50 [00:22<00:02,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 11, 13, 15, 16, 13, 16, 13] [14, 12, 21, 22, 19, 16, 15, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  92%|█████████▏| 46/50 [00:23<00:02,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 17, 12, 11, 8, 12, 12, 9] [8, 19, 13, 9, 9, 14, 18, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  94%|█████████▍| 47/50 [00:24<00:02,  1.44it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 17, 11, 18, 10, 11, 14, 16] [18, 18, 11, 17, 9, 10, 18, 20]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  96%|█████████▌| 48/50 [00:25<00:01,  1.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 14, 15, 15, 15, 17, 13, 14] [18, 18, 21, 16, 21, 20, 11, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Training:  98%|█████████▊| 49/50 [00:25<00:00,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [10, 14, 11, 10, 10, 10, 15] [11, 16, 11, 12, 8, 15, 16]\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 50/50 [00:26<00:00,  1.91it/s]\n","Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [16, 14, 16, 16, 16, 16, 11, 16] [20, 18, 20, 20, 20, 19, 15, 22]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  14%|█▍        | 1/7 [00:01<00:06,  1.11s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [14, 11, 16, 14, 16, 17, 12, 16] [20, 14, 20, 18, 20, 16, 13, 18]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  29%|██▊       | 2/7 [00:02<00:05,  1.03s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [15, 17, 10, 11, 9, 13, 17, 14] [16, 21, 12, 12, 10, 13, 15, 11]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  43%|████▎     | 3/7 [00:03<00:04,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 9, 10, 17, 18, 9, 10, 13] [15, 11, 12, 19, 18, 11, 11, 14]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  57%|█████▋    | 4/7 [00:04<00:02,  1.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11, 8, 16, 13, 16, 12, 12, 8] [13, 10, 14, 12, 18, 12, 12, 8]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating:  71%|███████▏  | 5/7 [00:05<00:02,  1.02s/it]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [13, 13, 13, 12, 13, 17, 14, 12] [21, 16, 14, 18, 23, 18, 14, 13]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [11] [19]\n","Epoch: 3 | Time: 0m 32s\n","\tTrain Loss: 4.720 | Train PPL: 112.211 | Train Accuracy: 48.250 %\n","\tVal Loss: 7.846 |  Val PPL: 2555.870 | Val Accuracy: 0.000 %\n","\tBLEU Score: 0.424\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Batch Sizes (Before Padding): [8, 2, 7, 10, 11, 15, 15, 11] [9, 3, 9, 13, 17, 17, 13, 15]\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/50 [00:00<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 194\u001b[0m\n\u001b[1;32m    191\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/romankasichhwa/Desktop/project/transformer/saved/model-1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(valid_loss))\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     draw(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,total_epoch\u001b[38;5;241m=\u001b[39mepoch, live_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    196\u001b[0m     draw(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m'\u001b[39m,total_epoch\u001b[38;5;241m=\u001b[39mepoch, live_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","Cell \u001b[0;32mIn[23], line 144\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(total_epoch, best_loss)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_epoch):\n\u001b[1;32m    143\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 144\u001b[0m     train_loss,train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     valid_loss, bleu, val_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, valid_iter, criterion, dataset\u001b[38;5;241m.\u001b[39mtrg_vocab_dict, device)\n\u001b[1;32m    146\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","Cell \u001b[0;32mIn[23], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     63\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     64\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[0;32m---> 65\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Compute accuracy\u001b[39;00m\n","File \u001b[0;32m~/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[0;32m~/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/minorproject/minor/lib/python3.11/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    388\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# dataset = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=lambda batch: custom_collate(batch, dataset.src_sos_idx, dataset.src_eos_idx, dataset.trg_sos_idx, dataset.trg_eos_idx, dataset.src_pad_idx, dataset.trg_pad_idx))\n","train_iter = DataLoader(dataset.train_data, batch_size=8, shuffle=True, collate_fn=lambda batch: custom_collate(batch, dataset.src_sos_idx, dataset.src_eos_idx, dataset.trg_sos_idx, dataset.trg_eos_idx, dataset.src_pad_idx, dataset.trg_pad_idx,dataset.src_vocab_dict,dataset.trg_vocab_dict))\n","test_iter = DataLoader(dataset.test_data, batch_size=8, shuffle=False, collate_fn=lambda batch: custom_collate(batch, dataset.src_sos_idx, dataset.src_eos_idx, dataset.trg_sos_idx, dataset.trg_eos_idx, dataset.src_pad_idx, dataset.trg_pad_idx,dataset.src_vocab_dict,dataset.trg_vocab_dict))\n","valid_iter = DataLoader(dataset.val_data, batch_size=8, shuffle=False, collate_fn=lambda batch: custom_collate(batch, dataset.src_sos_idx, dataset.src_eos_idx, dataset.trg_sos_idx, dataset.trg_eos_idx, dataset.src_pad_idx, dataset.trg_pad_idx,dataset.src_vocab_dict,dataset.trg_vocab_dict))\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.kaiming_uniform_(m.weight.data)\n","\n","\n","model = Transformer(src_pad_idx=dataset.src_pad_idx,\n","                    trg_pad_idx=dataset.trg_pad_idx,\n","                    trg_sos_idx=dataset.trg_sos_idx,\n","                    d_model=d_model,\n","                    enc_voc_size=dataset.enc_voc_size,\n","                    dec_voc_size=dataset.dec_voc_size,\n","                    max_len=max_len,\n","                    ffn_hidden=ffn_hidden,\n","                    n_head=n_heads,\n","                    n_layers=n_layers,\n","                    drop_prob=drop_prob,\n","                    device=device).to(device)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","model.apply(initialize_weights)\n","optimizer = Adam(params=model.parameters(),\n","                 lr=init_lr,\n","                 weight_decay=weight_decay,\n","                 eps=adam_eps)\n","\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n","                                                 verbose=True,\n","                                                 factor=factor,\n","                                                 patience=patience)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=dataset.src_pad_idx)\n","\n","\n","\n","def train(model, iterator, optimizer, criterion, clip):\n","    model.train()\n","    epoch_loss = 0\n","    correct_predictions = 0\n","    total_samples = 0\n","\n","    iterator = tqdm(iterator, total=len(iterator), desc='Training')\n","    \n","    for i, batch in enumerate(iterator):\n","        src, trg = batch\n","        src, trg = src.to(device), trg.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(src, trg[:, :-1])\n","        output_reshape = output.contiguous().view(-1, output.shape[-1])\n","        trg = trg[:, 1:].contiguous().view(-1)\n","\n","        loss = criterion(output_reshape, trg)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","        # Compute accuracy\n","        predicted = output_reshape.argmax(dim=1)\n","        correct_predictions += (predicted == trg).sum().item()\n","        total_samples += trg.size(0)\n","\n","        accuracy = correct_predictions / total_samples\n","\n","        # Update the progress bar description\n","#         iterator.set_description(f'Training Loss: {loss.item():.4f} | Accuracy: {accuracy:.4f}')\n","\n","    return epoch_loss / len(iterator), accuracy\n","\n","\n","\n","\n","def evaluate(model, iterator, criterion, target_vocab, device):\n","    model.eval()\n","    epoch_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","    accuracies = []\n","    references = []  # List to store reference sentences\n","    hypotheses = []  # List to store predicted sentences\n","\n","    iterator = tqdm(iterator, total=len(iterator), desc='Evaluating')\n","    \n","    with torch.no_grad():\n","        for i, (src_batch, trg_batch) in enumerate(iterator):\n","            src = src_batch\n","            trg = trg_batch\n","            src, trg = src.to(device), trg.to(device)\n","\n","            # Forward pass\n","            output = model(src, trg[:, :-1])\n","            output_reshape = output.contiguous().view(-1, output.shape[-1])\n","            output_reshape = output_reshape.to(device)\n","            trg = trg[:, 1:].contiguous().view(-1)\n","            trg = trg.to(output.device)\n","\n","            # Calculate loss\n","            loss = criterion(output_reshape, trg)\n","            epoch_loss += loss.item()\n","\n","            # Calculate accuracy\n","            predicted = output_reshape.argmax(dim=1)\n","            correct = (predicted == trg).sum().item()\n","            total_correct += correct\n","            total_samples += trg.size(0)\n","            accuracy = total_correct / total_samples\n","            accuracies.append(accuracy)\n","\n","            # Convert indices to words for BLEU calculation\n","            trg_words = [idx_to_word(sentence, target_vocab) for sentence in trg_batch.T]\n","            output_words = [idx_to_word(sentence, target_vocab) for sentence in output.argmax(dim=2).T]\n","\n","\n","            references.extend(trg_words)\n","            hypotheses.extend(output_words)\n","\n","            # print(f\"trg size: {trg.size()}\\n\")\n","            # print(f\"output size: {output.size()}\\n\")\n","\n","    # Calculate BLEU score\n","    bleu = get_bleu(hypotheses, references)\n","    \n","    return epoch_loss / len(iterator), accuracies, bleu\n","        \n","        \n","        \n","\n","\n","def run(total_epoch, best_loss):\n","    train_losses, test_losses, bleus, train_accuracies, val_accuracies = [], [], [], [],[]\n","    for step in range(total_epoch):\n","        start_time = time.time()\n","        train_loss,train_accuracy = train(model, train_iter, optimizer, criterion, clip)\n","        valid_loss, bleu, val_accuracy = evaluate(model, valid_iter, criterion, dataset.trg_vocab_dict, device)\n","        end_time = time.time()\n","\n","        if step > warmup:\n","            scheduler.step(valid_loss)\n","\n","        train_losses.append(train_loss)\n","        test_losses.append(valid_loss)\n","        bleus.append(bleu)\n","        train_accuracies.append(train_accuracy)  # Append train accuracy to the list\n","        val_accuracies.append(val_accuracy)  # Append accuracy to the list\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        if valid_loss < best_loss:\n","            best_loss = valid_loss\n","            # Save the model if needed\n","            # torch.save(model.state_dict(), '/kaggle/working/model-{0}.pt'.format(valid_loss))\n","\n","        # result_directory = '/kaggle/working/result'\n","        # os.makedirs(result_directory, exist_ok=True)\n","        \n","        # Save metrics to separate files\n","        with open('/Users/romankasichhwa/Desktop/project/transformer/saved/transformer-base/train.txt', 'w') as f:\n","            f.write(str(train_losses))\n","\n","        with open('/Users/romankasichhwa/Desktop/project/transformer/saved/transformer-base/bleu.txt', 'w') as f:\n","            f.write(str(bleus))\n","\n","        with open('/Users/romankasichhwa/Desktop/project/transformer/saved/transformer-base/test_loss.txt', 'w') as f:\n","            f.write(str(test_losses))\n","\n","        with open('/Users/romankasichhwa/Desktop/project/transformer/saved/transformer-base/train_accuracies.txt', 'w') as f:\n","            f.write(str(train_accuracies))\n","\n","        with open('/Users/romankasichhwa/Desktop/project/transformer/saved/transformer-base/val_accuracies.txt', 'w') as f:\n","            f.write(str(val_accuracies))\n","\n","        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n","        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Train Accuracy: {train_accuracies[-1]*100:.3f} %')\n","        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f} | Val Accuracy: {val_accuracies[-1]*100:.3f} %')\n","        print(f'\\tBLEU Score: {bleus[-1][-1]:.3f}')\n","\n","\n","        \n","        \n","\n","    torch.save(model.state_dict(), '/Users/romankasichhwa/Desktop/project/transformer/saved/model-1.pt'.format(valid_loss))\n","\n","if __name__ == '__main__':\n","    run(total_epoch=epoch, best_loss=inf)\n","    draw(mode='loss',total_epoch=epoch, live_update=True)\n","    draw(mode='bleu',total_epoch=epoch, live_update=True)\n","    draw(mode='accuracy',total_epoch=epoch, live_update=True)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T19:24:51.850926Z","iopub.status.busy":"2024-02-18T19:24:51.850195Z","iopub.status.idle":"2024-02-18T19:24:51.860589Z","shell.execute_reply":"2024-02-18T19:24:51.859609Z","shell.execute_reply.started":"2024-02-18T19:24:51.850896Z"},"trusted":true},"outputs":[],"source":["def draw(mode, live_update=False):\n","    plt.figure(figsize=(10, 6))\n","\n","    for draw_epoch in range(1, total_epoch + 1):  # Change the loop variable name to avoid conflict\n","        if mode == 'loss':\n","            train = read('/kaggle/working/result/train_loss.txt')[:draw_epoch]\n","            valid = read('/kaggle/working/result/test_loss.txt')[:draw_epoch]\n","            plt.plot(train, 'r', label='train')\n","            plt.plot(valid, 'b', label='validation')\n","            plt.title('Train/Validation Loss vs. Epoch')\n","            plt.legend(loc='upper right')\n","\n","        elif mode == 'bleu':\n","            bleu = read('/kaggle/working/result/bleu.txt')[:draw_epoch]\n","            plt.plot(bleu, 'b', label='BLEU score')\n","            plt.title('BLEU Score vs. Epoch')\n","            plt.legend(loc='lower right')\n","\n","        elif mode == 'accuracy':\n","            accuracy = read('/kaggle/working/result/accuracies.txt')[:draw_epoch]\n","            plt.plot(accuracy, 'g', label='accuracy')\n","            plt.title('Accuracy vs. Epoch')\n","            plt.legend(loc='lower right')\n","\n","        plt.xlabel('Epoch')\n","        plt.ylabel(mode.capitalize())\n","        plt.grid(True, which='both', axis='both')\n","\n","        if live_update:\n","            clear_output(wait=True)\n","            # display(plt.gcf())\n","            time.sleep(1)  # Optional: Pause for a moment between updates\n","        else:\n","            plt.show()"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-02-18T19:23:13.958932Z","iopub.status.busy":"2024-02-18T19:23:13.958456Z","iopub.status.idle":"2024-02-18T19:23:26.645556Z","shell.execute_reply":"2024-02-18T19:23:26.644329Z","shell.execute_reply.started":"2024-02-18T19:23:13.958901Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 34,473,713 trainable parameters\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n","No BLEU scores were calculated\n"]},{"ename":"TypeError","evalue":"unsupported operand type(s) for +: 'int' and 'list'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[57], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOTAL BLEU SCORE = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_bleu))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[57], line 59\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(num_examples)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#             total_bleu = sum(total_bleu) / len(total_bleu)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#             print('BLEU SCORE = {}'.format(total_bleu))\u001b[39;00m\n\u001b[1;32m     57\u001b[0m             batch_bleu\u001b[38;5;241m.\u001b[39mappend(total_bleu)\n\u001b[0;32m---> 59\u001b[0m         batch_bleu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(batch_bleu) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_bleu)\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOTAL BLEU SCORE = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_bleu))\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"]}],"source":["# test_iter=DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=lambda batch: custom_collate(batch, dataset.src_sos_idx, dataset.src_eos_idx, dataset.trg_sos_idx, dataset.trg_eos_idx, dataset.src_pad_idx, dataset.trg_pad_idx))\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","model = Transformer(src_pad_idx=dataset.src_pad_idx,\n","                    trg_pad_idx=dataset.trg_pad_idx,\n","                    trg_sos_idx=dataset.trg_sos_idx,\n","                    d_model=d_model,\n","                    enc_voc_size=dataset.enc_voc_size,\n","                    dec_voc_size=dataset.dec_voc_size,\n","                    max_len=max_len,\n","                    ffn_hidden=ffn_hidden,\n","                    n_head=n_heads,\n","                    n_layers=n_layers,\n","                    drop_prob=drop_prob,\n","                    device=device).to(device)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","\n","\n","def test_model(num_examples):\n","    iterator = test_iter\n","    model.load_state_dict(torch.load(\"/Users/romankasichhwa/Desktop/project/transformer/saved/model-1.pt\"))\n","\n","    with torch.no_grad():\n","        batch_bleu = []\n","        for i, batch in enumerate(iterator):\n","            src,trg = batch\n","            \n","            output = model(src, trg[:, :-1])\n","\n","            total_bleu = []\n","            for j in range(num_examples):\n","                try:\n","                    src_words = idx_to_word(src[j], dataset.src_vocab_dict)\n","                    trg_words = idx_to_word(trg[j], dataset.trg_vocab_dict)\n","                    output_words = output[j].max(dim=1)[1]\n","                    output_words = idx_to_word(output_words, dataset.trg_vocab)\n","\n","                    print('source :', src_words)\n","                    print('target :', trg_words)\n","                    print('predicted :', output_words)\n","                    print()\n","                    bleu = get_bleu(hypotheses=output_words.split(), reference=trg_words.split())\n","                    total_bleu.append(bleu)\n","                except:\n","                    pass\n","            try:\n","                total_bleu = sum(total_bleu) / len(total_bleu)\n","                print('BLEU SCORE = {}'.format(total_bleu))\n","            except ZeroDivisionError:\n","                print('No BLEU scores were calculated')\n","#             total_bleu = sum(total_bleu) / len(total_bleu)\n","#             print('BLEU SCORE = {}'.format(total_bleu))\n","            batch_bleu.append(total_bleu)\n","\n","        batch_bleu = sum(batch_bleu) / len(batch_bleu)\n","        print('TOTAL BLEU SCORE = {}'.format(batch_bleu))\n","\n","\n","if __name__ == '__main__':\n","    test_model(num_examples=batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4449763,"sourceId":7635967,"sourceType":"datasetVersion"},{"datasetId":4452857,"sourceId":7640342,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"minor","language":"python","name":"minor"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
